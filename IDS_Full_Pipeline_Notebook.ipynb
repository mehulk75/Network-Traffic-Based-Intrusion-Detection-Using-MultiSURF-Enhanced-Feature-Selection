{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330d7596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from imblearn.combine import SMOTEENN\n",
    "from skrebate import MultiSURF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6b9193",
   "metadata": {},
   "source": [
    "## NSL-KDD Dataset Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f3a5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NSL-KDD\n",
    "nsl_df = pd.read_csv(\"KDDTrain+.txt\")\n",
    "nsl_df.dropna(inplace=True)\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_cols = nsl_df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    nsl_df[col] = le.fit_transform(nsl_df[col])\n",
    "\n",
    "X_nsl = nsl_df.drop(\"label\", axis=1)\n",
    "y_nsl = nsl_df[\"label\"]\n",
    "y_nsl = y_nsl.apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "X_train_nsl, X_test_nsl, y_train_nsl, y_test_nsl = train_test_split(X_nsl, y_nsl, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_nsl = scaler.fit_transform(X_train_nsl)\n",
    "X_test_nsl = scaler.transform(X_test_nsl)\n",
    "\n",
    "fs = MultiSURF()\n",
    "X_train_nsl_fs = fs.fit_transform(X_train_nsl, y_train_nsl)\n",
    "X_test_nsl_fs = fs.transform(X_test_nsl)\n",
    "\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_nsl_resampled, y_nsl_resampled = smote_enn.fit_resample(X_train_nsl_fs, y_train_nsl)\n",
    "\n",
    "rf_nsl = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "start_time = time.time()\n",
    "rf_nsl.fit(X_nsl_resampled, y_nsl_resampled)\n",
    "latency_nsl = (time.time() - start_time) * 1000\n",
    "\n",
    "preds_nsl = rf_nsl.predict(X_test_nsl_fs)\n",
    "print(\"NSL-KDD Results:\")\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test_nsl, preds_nsl) * 100, 2), \"%\")\n",
    "print(\"F1 Score:\", round(f1_score(y_test_nsl, preds_nsl), 2))\n",
    "print(\"Latency:\", round(latency_nsl, 2), \"ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55231ef8",
   "metadata": {},
   "source": [
    "## CSE-CIC-IDS2018 Dataset Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1243d27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cic_df = pd.read_csv(\"CSE-CIC-IDS2018.csv\")\n",
    "cic_df.dropna(inplace=True)\n",
    "\n",
    "categorical_cols = cic_df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    cic_df[col] = le.fit_transform(cic_df[col])\n",
    "\n",
    "X_cic = cic_df.drop(\"Label\", axis=1)\n",
    "y_cic = cic_df[\"Label\"]\n",
    "y_cic = y_cic.apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "X_train_cic, X_test_cic, y_train_cic, y_test_cic = train_test_split(X_cic, y_cic, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_cic = scaler.fit_transform(X_train_cic)\n",
    "X_test_cic = scaler.transform(X_test_cic)\n",
    "\n",
    "fs_cic = MultiSURF()\n",
    "X_train_cic_fs = fs_cic.fit_transform(X_train_cic, y_train_cic)\n",
    "X_test_cic_fs = fs_cic.transform(X_test_cic)\n",
    "\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_cic_resampled, y_cic_resampled = smote_enn.fit_resample(X_train_cic_fs, y_train_cic)\n",
    "\n",
    "rf_cic = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "start_time = time.time()\n",
    "rf_cic.fit(X_cic_resampled, y_cic_resampled)\n",
    "latency_cic = (time.time() - start_time) * 1000\n",
    "\n",
    "preds_cic = rf_cic.predict(X_test_cic_fs)\n",
    "print(\"CSE-CIC-IDS2018 Results:\")\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test_cic, preds_cic) * 100, 2), \"%\")\n",
    "print(\"F1 Score:\", round(f1_score(y_test_cic, preds_cic), 2))\n",
    "print(\"Latency:\", round(latency_cic, 2), \"ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dd0e93",
   "metadata": {},
   "source": [
    "## Custom Curated Dataset Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d101f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "permissions_df = pd.read_csv(\"Permissions vector table 1,12,000 Apps, 1% perms (2).csv\")\n",
    "hardware_df = pd.read_csv(\"Hardware_comp_vector_table.csv\")\n",
    "intents_df = pd.read_csv(\"Intents 56000normal_56000mal_with_app_names_0_and_1_type.csv\")\n",
    "\n",
    "permissions_df.rename(columns={permissions_df.columns[0]: \"apk\"}, inplace=True)\n",
    "hardware_df.rename(columns={hardware_df.columns[0]: \"apk\"}, inplace=True)\n",
    "intents_df.rename(columns={intents_df.columns[0]: \"apk\"}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "def clean_apk_names(df):\n",
    "    df[\"apk\"] = df[\"apk\"].astype(str).str.strip().str.replace('\"', '').str.replace(\"0000- \", \"\").str.replace(\"0000-\", \"\")\n",
    "    return df\n",
    "\n",
    "permissions_df = clean_apk_names(permissions_df)\n",
    "hardware_df = clean_apk_names(hardware_df)\n",
    "intents_df = clean_apk_names(intents_df)\n",
    "\n",
    "\n",
    "# Use inner join to keep only common APKs\n",
    "merged_df = permissions_df.merge(hardware_df, on=\"apk\", how=\"inner\")\n",
    "merged_df = merged_df.merge(intents_df, on=\"apk\", how=\"inner\")\n",
    "\n",
    "print(\"Shape of merged dataset:\", merged_df.shape)\n",
    "print(\"Number of unique APKs:\", merged_df[\"apk\"].nunique())\n",
    "\n",
    "\n",
    "merged_df.to_csv(\"Custom_Curated_Android_Dataset.csv\", index=False)\n",
    "\n",
    "\n",
    "categorical_cols = merged_df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    merged_df[col] = le.fit_transform(merged_df[col])\n",
    "\n",
    "X_custom = merged_df.drop(\"Label\", axis=1)\n",
    "y_custom = merged_df[\"Label\"]\n",
    "y_custom = y_custom.apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "X_train_cus, X_test_cus, y_train_cus, y_test_cus = train_test_split(X_custom, y_custom, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_cus = scaler.fit_transform(X_train_cus)\n",
    "X_test_cus = scaler.transform(X_test_cus)\n",
    "\n",
    "fs_cus = MultiSURF()\n",
    "X_train_cus_fs = fs_cus.fit_transform(X_train_cus, y_train_cus)\n",
    "X_test_cus_fs = fs_cus.transform(X_test_cus)\n",
    "\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_cus_resampled, y_cus_resampled = smote_enn.fit_resample(X_train_cus_fs, y_train_cus)\n",
    "\n",
    "rf_cus = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "start_time = time.time()\n",
    "rf_cus.fit(X_cus_resampled, y_cus_resampled)\n",
    "latency_cus = (time.time() - start_time) * 1000\n",
    "\n",
    "preds_cus = rf_cus.predict(X_test_cus_fs)\n",
    "print(\"Custom Dataset Results:\")\n",
    "print(\"Accuracy:\", round(accuracy_score(y_test_cus, preds_cus) * 100, 2), \"%\")\n",
    "print(\"F1 Score:\", round(f1_score(y_test_cus, preds_cus), 2))\n",
    "print(\"Latency:\", round(latency_cus, 2), \"ms\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
